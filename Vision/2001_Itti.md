# Title: Computational Modeling of Visual Attention
# Authors: Itti and Koch (2001)

### Main Takeaway: Trends in bottom-up, image-based control of attentional deployment
1. Perceptual saliency - sorrounding context
2. Saliency map - control strategy
3. Inhibition of return: do not return to previously attended location
4. Interplay attention and eye movements
5. Tasks constrain selection of attended locations

# General Notes:

* 2 component framework:
    1. bottom-up: image-based saliency cues - Fast
        * pre-attentive = across entire visual field - hierarchical centre-surround mechanisms
        * 25 to 50 ms per item
    2. top-down: task dependent cues - Slow
        * variable selection criteria
        * volitional deployment of attention - 200ms

* Attention = info-processing bottleneck
    * allows only small part of sensory info into short-term memory and visual awareness
    * reduction of problem into smaller computational problems
    * triggers behavior and enhances cortical representation at attended location
    * focal visual attention = stage-light

* 2 parallel hierarchical streams of visual info processing (LGN -> V1 | SC):
    - dorsal - IT: spatial localization and attention/gaze direction towards object of interest
    - ventral - PPC: recognition and identification of visual stimuli
        - receive attentional feedback modulation and are involved in representation of attended locations and objects
    - Integration of both streams in PFC

* Neuronal tuning: increasingly more specialized from low to high-level visual areas

* Attention = modulates top-down early visual processing
    * enhanced gain, biased/intensified competition, enhanced spatial resolution, modulated background activity, effective stimulus strength, noise
    * modulation equivalent to increase in stimulus strength
    * activates winner-take-all competition among neurons tuned to different orientations/spatial frequencies within hypercolumn

* Response of neuron tuned to intensity centre-surround contrast can be computed by convolving luminance channel of inout by diff-of-gaussians filter - Mexican hat

* Response of orientation-selective neuron can be computed through convolution by gabor wavelets - resemble impulse response functions

* Early feature detection:
    1. Different features contribute with different strengths - weighting can be influenced according to demands of task (top-down modulation and training)
    2. At given visual location there is little evidence for strong interactions across different visual modalities (e.g. color/orientation)
    3. Within given feature dim, strong local interactions between filters sensitive to different properties of that feature have been characterized
    4. Botttom-up attention is guided by feature contrast and not local absolute feature strength

* Comp consequences of non-classical surround modulation:
    1. broad inhibitory effect when neuron excited by preferred stimulus but that stim extends beyond neurons cRF.
    2. Long-range excitatory connections in V1 = enhance responses of orientation-selective neuorns when stimuli extends to form contour - perceptual grouping!
    - RESULT: Sparse cortical activaty in primate free-viewing scenes compared to small lab stimuli presented in isolation

* saliency map - combines multiple feature map (scalar 2d) - attention = focus on highest activity location (winner of spatial competition)
    * bottum-up - feature contrast + top-down feature weighting
    * competition for saliency is refined at each level of processing - pruning of loosers
    * Conflict: centralized map vs distributive nature

* Inhibition of return = inhib tagging of prev attended locations
    * measure by reaction times: visual processing at recently attended locations slower!
    * implements form of short-term memory - "frame-of-reference" problem

* Recognition: Scan of saliency map by focus of attention - interplay winner-take-all and IOR
    * Computation of sufficient recognition score

# Questions:
* How to include into machine vision DL framework? - Need sequential setting with a form of model-based EE trade-off mechanism
* How can manual filter banks ever win against high-dim optimization of Deep Learning? There is just not enough domain knowledge.
